# ğŸš€ Multi-Threaded Web Crawler

A concurrent web crawler built using **Java + Spring Boot** that performs BFS-based crawling with depth limits, page limits, and thread-safe aggregation.
ğŸ“‚ GitHub: https://github.com/harshitsinha11/Web-Crawler  

---

## ğŸ“Œ Overview

This project implements a **multi-threaded web crawler** that:

- Accepts up to 5 seed URLs
- Crawls pages concurrently using a fixed thread pool
- Performs Breadth-First Search (BFS)
- Enforces maximum depth (default: 5)
- Enforces maximum page count (default: 30)
- Extracts structured metadata:
  - Page Title
  - Word Count
  - Text Snippet (first 1000 characters)
- Returns results via a REST API
- Includes a modern, premium dark-themed frontend UI

---

## ğŸ§  Architecture Overview

```
Client (HTML / JS)
â†“
REST Controller (/crawl/start)
â†“
CrawlService
â†“
ExecutorService (5 Worker Threads)
â†“
BlockingQueue<CrawlData> â†’ BFS Traversal
ConcurrentHashMap<String, PageData> â†’ Thread-safe Storage
```

---

## âš™ï¸ Concurrency Design

| Component | Purpose |
|------------|----------|
| `ExecutorService` | Fixed-size worker pool (5 threads) |
| `BlockingQueue` | BFS crawl task coordination |
| `ConcurrentHashMap` | Thread-safe result aggregation |
| `AtomicInteger` | Global page limit enforcement |

### Why Fixed Thread Pool?

- Predictable concurrency
- Controlled resource usage
- Suitable for I/O-bound workloads
- Prevents uncontrolled thread growth

---

## ğŸ“‚ Project Structure

```
multithreaded-web-crawler/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/dev/harshit/crawler/
â”‚   â”‚   â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CrawlController.java
â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CrawlService.java
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PageCrawl.java
â”‚   â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PageData.java
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CrawlResponse.java
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ HtmlUtils.java
â”‚   â”‚   â”‚   â””â”€â”€ CrawlerApplication.java
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â”œâ”€â”€ static/
â”‚   â”‚       â”‚   â”œâ”€â”€ index.html
â”‚   â”‚       â”‚   â”œâ”€â”€ css/
â”‚   â”‚       â”‚   â””â”€â”€ js/
â”‚   â”‚       â””â”€â”€ application.properties
â”‚
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```
---

## ğŸ”„ How It Works

### 1ï¸âƒ£ Input

Frontend sends up to 5 seed URLs via:

### Endpoint

```http
POST /crawl/start
```

---

### 2ï¸âƒ£ Initialization

- Seed URLs added to `BlockingQueue`
- 5 worker threads created using `ExecutorService`

---

### 3ï¸âƒ£ Worker Execution

Each worker thread:

1. Polls URL from queue  
2. Skips if:
   - Depth exceeded
   - Already visited
3. Crawls page
4. Extracts metadata
5. Extracts child links
6. Adds new tasks to queue (if depth allows)
7. Stores result in `ConcurrentHashMap`

---

### 4ï¸âƒ£ Termination

- Stops when `MAX_PAGES` reached
- Uses `awaitTermination()` to wait for all threads
- Builds final `CrawlResponse`

---

## ğŸ¨ Frontend Features

- Dynamic URL input (max 5)
- Remove URL option
- Loading spinner
- Glassmorphism result cards
- Hover glow animation
- Modern luxury dark UI

---

## ğŸ›  Tech Stack

### Backend
- Java 17+
- Spring Boot
- JSoup
- Maven
- ExecutorService

### Frontend
- HTML
- CSS (Glassmorphism UI)
- Vanilla JavaScript

---

## â–¶ï¸ Running Locally

### 1. Clone the Repository
```bash
git clone https://github.com/harshitsinha11/Web-Crawler.git
```

### 2. Run Application
```bash
mvn spring-boot:run
```

### 3. Access Application
```bash
http://localhost:9000/index.html
```
---

## ğŸ“ˆ Future Improvements

- Domain restriction support
- Crawl politeness delay
- Async job queue architecture
- Database persistence
- Distributed crawling
- Graph visualization of crawl tree

---

## ğŸ¯ Learning Outcomes

This project strengthened understanding of:

- Thread lifecycle management
- Concurrency safety
- Shared state synchronization
- BFS in concurrent systems
- REST API design
- Frontend + backend integration
- Production deployment

---

## ğŸ“· Demo

### ğŸ  Home
![Home](screenshots/Home.png)

### ğŸ§µ Code
![Code](screenshots/Code.png)

### ğŸŒ Crawled Results
![Crawled](screenshots/Crawled.png)

### ğŸš€ Logs
![Demo](screenshots/Logs.png)

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

Harshit Sinha  
B.Tech Computer Science  
Passionate about backend systems, concurrency and cloud computing.


